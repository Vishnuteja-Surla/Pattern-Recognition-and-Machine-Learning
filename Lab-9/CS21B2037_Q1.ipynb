{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defined Classes and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def __init__(self, n=0):\n",
    "        self.d1 = n\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.d = len(X[0])\n",
    "        self.classes = np.unique(y)\n",
    "        self.no_of_classes = len(self.classes)\n",
    "        self.split_X = []\n",
    "        for c in self.classes:\n",
    "            class_X = []\n",
    "            for i in range(len(y)):\n",
    "                if y[i] == c:\n",
    "                    class_X.append(X[i])\n",
    "            self.split_X.append(class_X)\n",
    "        self.split_X = np.array(self.split_X)\n",
    "\n",
    "        # Step-1: Finding Mean Vectors for each class\n",
    "        self.mean_vectors = []\n",
    "        for X_class in self.split_X:\n",
    "            self.mean_vectors.append(np.mean(X_class, axis=0))\n",
    "        self.mean_vectors = np.array(self.mean_vectors)\n",
    "\n",
    "        # Step-2: Computing Scatter Matrices\n",
    "        # Part-A: Within class Scatter Matrix\n",
    "        self.covariance_matrices = []\n",
    "        for X_class in self.split_X:\n",
    "            self.covariance_matrices.append(np.cov(X_class, rowvar=False))\n",
    "        self.covariance_matrices = np.array(self.covariance_matrices)\n",
    "        self.Sw = np.zeroes((self.d, self.d))\n",
    "        for i in range(self.no_of_classes):\n",
    "            self.Sw += (len(self.split_X[i])-1)*self.covariance_matrices[i]\n",
    "        # Part-B: Between class Scatter Matrix\n",
    "        self.overall_mean = np.mean(X, axis=0)\n",
    "        self.Sb = np.zeroes((self.d, self.d))\n",
    "        for i in range(self.no_of_classes):\n",
    "            mean_vec = self.mean_vectors[i].reshape(self.d, 1)\n",
    "            ovr_mean = self.overall_mean.reshpae(self.d, 1)\n",
    "            self.Sb += len(self.split_X[i])*(mean_vec - ovr_mean).dot((mean_vec - ovr_mean).T)\n",
    "\n",
    "        # Step-3: Finding Eigen Values and Vectors\n",
    "        self.eig_vals, self.eig_vecs = np.linlg.eig(np.linalg.inv(self.Sw).dot(self.Sb))\n",
    "\n",
    "        # Step-4: Sorting Eigen Values and deciding on d'\n",
    "        ind = np.argsort(self.eigen_values)[::-1]\n",
    "        self.sorted_eig_vals = self.eig_vals[ind]\n",
    "        self.sorted_eig_vecs = self.eig_vecs[ind]\n",
    "        if self.d1 < 1:\n",
    "            if self.d1 <= 0:\n",
    "                self.d1 = 0.99\n",
    "            self.total_variance = np.sum(self.sorted_eig_vals)\n",
    "            self.selected_eig_values = []\n",
    "            cum_variance = 0\n",
    "            i = 0\n",
    "            while cum_variance < self.d1 * self.total_variance:\n",
    "                cum_variance += self.sorted_eig_vals[i]\n",
    "                self.selected_eig_values.append(self.sorted_eig_vals[i])\n",
    "                i += 1\n",
    "            self.selected_eig_values = np.array(self.selected_eig_values)\n",
    "            self.d1 = len(self.selected_eig_values)\n",
    "        self.final_eig_vecs = self.sorted_eig_vecs[:, :self.d1]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X1 = np.dot(X, self.final_eig_vecs)\n",
    "        return X1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0 Unnamed: 1         0         1         2         3         4  \\\n0             1       male -0.066420  0.151611  0.027740  0.052771 -0.066105   \n1             2       male -0.030614  0.049667  0.008084 -0.050324  0.007649   \n2             3       male -0.096178  0.061127  0.035326 -0.035388 -0.090728   \n3             4       male -0.103057  0.085044  0.078333 -0.035873 -0.028163   \n4             5       male -0.125815  0.120046  0.023131 -0.042901  0.038215   \n..          ...        ...       ...       ...       ...       ...       ...   \n795         796     female -0.164731  0.064301  0.058630 -0.017420 -0.157600   \n796         797     female -0.095308  0.051095  0.092913 -0.101745 -0.083153   \n797         798     female -0.202852  0.037039  0.079731 -0.047156 -0.140062   \n798         799     female -0.088300  0.063530  0.049627 -0.026011 -0.172773   \n799         800     female -0.156201  0.055165  0.142716 -0.115393 -0.128982   \n\n            5         6         7  ...       118       119       120  \\\n0   -0.041232 -0.002637 -0.158467  ...  0.025989 -0.001087  0.027260   \n1   -0.063818 -0.019530 -0.119905  ...  0.044229 -0.023900 -0.028108   \n2   -0.018634 -0.024315 -0.139786  ...  0.111141  0.059436 -0.029222   \n3    0.004924  0.007829 -0.017016  ...  0.100793 -0.002644 -0.023388   \n4   -0.049677 -0.054258 -0.130758  ...  0.090197  0.067527  0.039926   \n..        ...       ...       ...  ...       ...       ...       ...   \n795 -0.022536  0.002864 -0.072739  ...  0.095115  0.007198 -0.004655   \n796 -0.028159  0.009090 -0.114513  ...  0.056078  0.119846  0.087470   \n797 -0.080246  0.057668 -0.122083  ...  0.066954  0.035684 -0.023112   \n798  0.086218  0.042710 -0.161852  ...  0.039460  0.067547  0.040426   \n799 -0.139830 -0.037305 -0.101402  ...  0.024955  0.066980 -0.002332   \n\n          121       122       123       124       125       126       127  \n0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n..        ...       ...       ...       ...       ...       ...       ...  \n795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n\n[800 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>118</th>\n      <th>119</th>\n      <th>120</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>male</td>\n      <td>-0.066420</td>\n      <td>0.151611</td>\n      <td>0.027740</td>\n      <td>0.052771</td>\n      <td>-0.066105</td>\n      <td>-0.041232</td>\n      <td>-0.002637</td>\n      <td>-0.158467</td>\n      <td>...</td>\n      <td>0.025989</td>\n      <td>-0.001087</td>\n      <td>0.027260</td>\n      <td>-0.046754</td>\n      <td>-0.118619</td>\n      <td>-0.163774</td>\n      <td>-0.000590</td>\n      <td>-0.076400</td>\n      <td>0.107497</td>\n      <td>0.001567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>male</td>\n      <td>-0.030614</td>\n      <td>0.049667</td>\n      <td>0.008084</td>\n      <td>-0.050324</td>\n      <td>0.007649</td>\n      <td>-0.063818</td>\n      <td>-0.019530</td>\n      <td>-0.119905</td>\n      <td>...</td>\n      <td>0.044229</td>\n      <td>-0.023900</td>\n      <td>-0.028108</td>\n      <td>0.040618</td>\n      <td>-0.146579</td>\n      <td>-0.141244</td>\n      <td>0.016162</td>\n      <td>0.017638</td>\n      <td>0.080610</td>\n      <td>-0.015930</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>male</td>\n      <td>-0.096178</td>\n      <td>0.061127</td>\n      <td>0.035326</td>\n      <td>-0.035388</td>\n      <td>-0.090728</td>\n      <td>-0.018634</td>\n      <td>-0.024315</td>\n      <td>-0.139786</td>\n      <td>...</td>\n      <td>0.111141</td>\n      <td>0.059436</td>\n      <td>-0.029222</td>\n      <td>0.042115</td>\n      <td>-0.222173</td>\n      <td>-0.116908</td>\n      <td>0.093428</td>\n      <td>0.017391</td>\n      <td>0.057652</td>\n      <td>0.086116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>male</td>\n      <td>-0.103057</td>\n      <td>0.085044</td>\n      <td>0.078333</td>\n      <td>-0.035873</td>\n      <td>-0.028163</td>\n      <td>0.004924</td>\n      <td>0.007829</td>\n      <td>-0.017016</td>\n      <td>...</td>\n      <td>0.100793</td>\n      <td>-0.002644</td>\n      <td>-0.023388</td>\n      <td>0.029497</td>\n      <td>-0.139830</td>\n      <td>-0.119243</td>\n      <td>0.005306</td>\n      <td>-0.015100</td>\n      <td>0.161575</td>\n      <td>0.062462</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>male</td>\n      <td>-0.125815</td>\n      <td>0.120046</td>\n      <td>0.023131</td>\n      <td>-0.042901</td>\n      <td>0.038215</td>\n      <td>-0.049677</td>\n      <td>-0.054258</td>\n      <td>-0.130758</td>\n      <td>...</td>\n      <td>0.090197</td>\n      <td>0.067527</td>\n      <td>0.039926</td>\n      <td>0.047469</td>\n      <td>-0.056852</td>\n      <td>-0.076700</td>\n      <td>0.004966</td>\n      <td>0.028171</td>\n      <td>0.026041</td>\n      <td>0.084135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>796</td>\n      <td>female</td>\n      <td>-0.164731</td>\n      <td>0.064301</td>\n      <td>0.058630</td>\n      <td>-0.017420</td>\n      <td>-0.157600</td>\n      <td>-0.022536</td>\n      <td>0.002864</td>\n      <td>-0.072739</td>\n      <td>...</td>\n      <td>0.095115</td>\n      <td>0.007198</td>\n      <td>-0.004655</td>\n      <td>0.023957</td>\n      <td>-0.170753</td>\n      <td>-0.136630</td>\n      <td>0.041614</td>\n      <td>0.031600</td>\n      <td>0.019064</td>\n      <td>0.004384</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>797</td>\n      <td>female</td>\n      <td>-0.095308</td>\n      <td>0.051095</td>\n      <td>0.092913</td>\n      <td>-0.101745</td>\n      <td>-0.083153</td>\n      <td>-0.028159</td>\n      <td>0.009090</td>\n      <td>-0.114513</td>\n      <td>...</td>\n      <td>0.056078</td>\n      <td>0.119846</td>\n      <td>0.087470</td>\n      <td>0.017481</td>\n      <td>-0.096594</td>\n      <td>-0.084553</td>\n      <td>0.037709</td>\n      <td>0.030732</td>\n      <td>-0.083713</td>\n      <td>0.064970</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>798</td>\n      <td>female</td>\n      <td>-0.202852</td>\n      <td>0.037039</td>\n      <td>0.079731</td>\n      <td>-0.047156</td>\n      <td>-0.140062</td>\n      <td>-0.080246</td>\n      <td>0.057668</td>\n      <td>-0.122083</td>\n      <td>...</td>\n      <td>0.066954</td>\n      <td>0.035684</td>\n      <td>-0.023112</td>\n      <td>-0.030452</td>\n      <td>-0.154243</td>\n      <td>-0.188270</td>\n      <td>0.071086</td>\n      <td>0.037384</td>\n      <td>-0.006257</td>\n      <td>0.039977</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>799</td>\n      <td>female</td>\n      <td>-0.088300</td>\n      <td>0.063530</td>\n      <td>0.049627</td>\n      <td>-0.026011</td>\n      <td>-0.172773</td>\n      <td>0.086218</td>\n      <td>0.042710</td>\n      <td>-0.161852</td>\n      <td>...</td>\n      <td>0.039460</td>\n      <td>0.067547</td>\n      <td>0.040426</td>\n      <td>0.028007</td>\n      <td>-0.154515</td>\n      <td>-0.127736</td>\n      <td>0.046967</td>\n      <td>0.009701</td>\n      <td>-0.016942</td>\n      <td>0.048071</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>800</td>\n      <td>female</td>\n      <td>-0.156201</td>\n      <td>0.055165</td>\n      <td>0.142716</td>\n      <td>-0.115393</td>\n      <td>-0.128982</td>\n      <td>-0.139830</td>\n      <td>-0.037305</td>\n      <td>-0.101402</td>\n      <td>...</td>\n      <td>0.024955</td>\n      <td>0.066980</td>\n      <td>-0.002332</td>\n      <td>-0.045738</td>\n      <td>-0.110557</td>\n      <td>-0.014995</td>\n      <td>-0.002124</td>\n      <td>-0.010298</td>\n      <td>-0.028856</td>\n      <td>0.075323</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 130 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('gender.csv')\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Train Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "types = dataset.iloc[:, 1].unique()\n",
    "test_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "for t in types:\n",
    "    type_df = dataset[dataset.iloc[:, 1] == t]\n",
    "    train_df = pd.concat([train_df, type_df.iloc[10:]])\n",
    "    test_df = pd.concat([test_df, type_df.iloc[:10]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0 Unnamed: 1         0         1         2         3         4  \\\n0             1       male -0.066420  0.151611  0.027740  0.052771 -0.066105   \n1             2       male -0.030614  0.049667  0.008084 -0.050324  0.007649   \n2             3       male -0.096178  0.061127  0.035326 -0.035388 -0.090728   \n3             4       male -0.103057  0.085044  0.078333 -0.035873 -0.028163   \n4             5       male -0.125815  0.120046  0.023131 -0.042901  0.038215   \n5             6       male -0.149119  0.125288  0.142323 -0.009087 -0.031394   \n6             7       male -0.139035  0.073513 -0.001770 -0.034225 -0.101610   \n7             8       male -0.074126 -0.000669  0.004166 -0.082413 -0.096091   \n8             9       male -0.166220  0.042769 -0.031647 -0.036892 -0.143837   \n9            10       male -0.185770  0.154008  0.073184 -0.070829 -0.144617   \n399         400     female  0.039844  0.070357  0.130196 -0.007683 -0.077825   \n400         401     female  0.001747  0.185678  0.073260  0.042142 -0.088674   \n401         402     female -0.091598  0.095340  0.072125 -0.092276 -0.079953   \n402         403     female -0.018751  0.088572  0.068894 -0.065700 -0.115126   \n403         404     female -0.130889  0.093262  0.122244 -0.110014 -0.157625   \n404         405     female -0.037433  0.078158  0.118061 -0.117658 -0.194807   \n405         406     female -0.048322  0.063833  0.110804 -0.096333 -0.145212   \n406         407     female -0.102973  0.046464  0.019684 -0.087742 -0.086486   \n407         408     female -0.134824  0.093314  0.103505 -0.054522 -0.066692   \n408         409     female -0.086950  0.104945  0.093125 -0.138791 -0.111283   \n\n            5         6         7  ...       118       119       120  \\\n0   -0.041232 -0.002637 -0.158467  ...  0.025989 -0.001087  0.027260   \n1   -0.063818 -0.019530 -0.119905  ...  0.044229 -0.023900 -0.028108   \n2   -0.018634 -0.024315 -0.139786  ...  0.111141  0.059436 -0.029222   \n3    0.004924  0.007829 -0.017016  ...  0.100793 -0.002644 -0.023388   \n4   -0.049677 -0.054258 -0.130758  ...  0.090197  0.067527  0.039926   \n5   -0.123533  0.043598 -0.063999  ...  0.060833  0.089529 -0.034872   \n6    0.065105 -0.014420 -0.054993  ...  0.081007 -0.002164  0.060377   \n7   -0.021992  0.009714 -0.056961  ...  0.050497  0.038932  0.023520   \n8   -0.040566  0.042541 -0.122923  ...  0.014732 -0.049135  0.081770   \n9   -0.019732 -0.019418 -0.004675  ...  0.093317  0.035101 -0.147997   \n399 -0.021298 -0.024133 -0.085105  ...  0.105510  0.081928 -0.033337   \n400  0.028186 -0.027830 -0.064211  ...  0.123615  0.030036  0.041442   \n401  0.047782 -0.004701 -0.092005  ...  0.011370  0.144719  0.089139   \n402  0.024339 -0.028420 -0.159320  ...  0.010345  0.095309  0.012255   \n403 -0.036781  0.073908 -0.098571  ...  0.003229  0.049330  0.059733   \n404 -0.045464 -0.014104 -0.158824  ...  0.043848 -0.009760  0.043486   \n405  0.008218  0.012496 -0.056971  ...  0.036783  0.064837  0.140861   \n406 -0.044946 -0.088026 -0.248814  ...  0.091401  0.096097  0.019656   \n407 -0.039892 -0.005544 -0.140088  ... -0.043587  0.042913 -0.062721   \n408 -0.078399 -0.063179 -0.155705  ...  0.125923  0.069823  0.081179   \n\n          121       122       123       124       125       126       127  \n0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n5    0.057080 -0.137162 -0.072522  0.052731 -0.141460  0.019018  0.085765  \n6    0.080294 -0.139369 -0.150245  0.078657  0.024194  0.062180  0.036039  \n7   -0.090260 -0.147692 -0.008296  0.007609 -0.026687 -0.017523 -0.038310  \n8   -0.027199 -0.096941 -0.094661  0.057797 -0.101063  0.061373  0.062176  \n9   -0.046010 -0.087777 -0.100660  0.036190  0.012158  0.032304  0.085996  \n399 -0.023604 -0.167003 -0.059075  0.053074  0.080940  0.011467 -0.021999  \n400 -0.012818 -0.119177 -0.165786 -0.075368 -0.017690  0.067028  0.036452  \n401 -0.059767 -0.111235 -0.055420  0.006283  0.016900 -0.081676  0.022809  \n402 -0.033010 -0.097720 -0.218889  0.077764  0.045943  0.010856  0.100522  \n403 -0.023820 -0.098432 -0.034316  0.075131 -0.029204 -0.020707  0.031028  \n404  0.020251 -0.115420 -0.040023  0.099409 -0.032240  0.037601 -0.020016  \n405 -0.063511 -0.156427 -0.067221  0.025938  0.016019  0.016852  0.140859  \n406  0.017288 -0.176065 -0.060538  0.095438 -0.088858  0.049312  0.019009  \n407 -0.065257 -0.232838 -0.136345  0.017268 -0.102133  0.014161  0.011314  \n408  0.004632 -0.121078 -0.018539  0.092550 -0.081236  0.073335  0.056886  \n\n[20 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>118</th>\n      <th>119</th>\n      <th>120</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>male</td>\n      <td>-0.066420</td>\n      <td>0.151611</td>\n      <td>0.027740</td>\n      <td>0.052771</td>\n      <td>-0.066105</td>\n      <td>-0.041232</td>\n      <td>-0.002637</td>\n      <td>-0.158467</td>\n      <td>...</td>\n      <td>0.025989</td>\n      <td>-0.001087</td>\n      <td>0.027260</td>\n      <td>-0.046754</td>\n      <td>-0.118619</td>\n      <td>-0.163774</td>\n      <td>-0.000590</td>\n      <td>-0.076400</td>\n      <td>0.107497</td>\n      <td>0.001567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>male</td>\n      <td>-0.030614</td>\n      <td>0.049667</td>\n      <td>0.008084</td>\n      <td>-0.050324</td>\n      <td>0.007649</td>\n      <td>-0.063818</td>\n      <td>-0.019530</td>\n      <td>-0.119905</td>\n      <td>...</td>\n      <td>0.044229</td>\n      <td>-0.023900</td>\n      <td>-0.028108</td>\n      <td>0.040618</td>\n      <td>-0.146579</td>\n      <td>-0.141244</td>\n      <td>0.016162</td>\n      <td>0.017638</td>\n      <td>0.080610</td>\n      <td>-0.015930</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>male</td>\n      <td>-0.096178</td>\n      <td>0.061127</td>\n      <td>0.035326</td>\n      <td>-0.035388</td>\n      <td>-0.090728</td>\n      <td>-0.018634</td>\n      <td>-0.024315</td>\n      <td>-0.139786</td>\n      <td>...</td>\n      <td>0.111141</td>\n      <td>0.059436</td>\n      <td>-0.029222</td>\n      <td>0.042115</td>\n      <td>-0.222173</td>\n      <td>-0.116908</td>\n      <td>0.093428</td>\n      <td>0.017391</td>\n      <td>0.057652</td>\n      <td>0.086116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>male</td>\n      <td>-0.103057</td>\n      <td>0.085044</td>\n      <td>0.078333</td>\n      <td>-0.035873</td>\n      <td>-0.028163</td>\n      <td>0.004924</td>\n      <td>0.007829</td>\n      <td>-0.017016</td>\n      <td>...</td>\n      <td>0.100793</td>\n      <td>-0.002644</td>\n      <td>-0.023388</td>\n      <td>0.029497</td>\n      <td>-0.139830</td>\n      <td>-0.119243</td>\n      <td>0.005306</td>\n      <td>-0.015100</td>\n      <td>0.161575</td>\n      <td>0.062462</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>male</td>\n      <td>-0.125815</td>\n      <td>0.120046</td>\n      <td>0.023131</td>\n      <td>-0.042901</td>\n      <td>0.038215</td>\n      <td>-0.049677</td>\n      <td>-0.054258</td>\n      <td>-0.130758</td>\n      <td>...</td>\n      <td>0.090197</td>\n      <td>0.067527</td>\n      <td>0.039926</td>\n      <td>0.047469</td>\n      <td>-0.056852</td>\n      <td>-0.076700</td>\n      <td>0.004966</td>\n      <td>0.028171</td>\n      <td>0.026041</td>\n      <td>0.084135</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>male</td>\n      <td>-0.149119</td>\n      <td>0.125288</td>\n      <td>0.142323</td>\n      <td>-0.009087</td>\n      <td>-0.031394</td>\n      <td>-0.123533</td>\n      <td>0.043598</td>\n      <td>-0.063999</td>\n      <td>...</td>\n      <td>0.060833</td>\n      <td>0.089529</td>\n      <td>-0.034872</td>\n      <td>0.057080</td>\n      <td>-0.137162</td>\n      <td>-0.072522</td>\n      <td>0.052731</td>\n      <td>-0.141460</td>\n      <td>0.019018</td>\n      <td>0.085765</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>male</td>\n      <td>-0.139035</td>\n      <td>0.073513</td>\n      <td>-0.001770</td>\n      <td>-0.034225</td>\n      <td>-0.101610</td>\n      <td>0.065105</td>\n      <td>-0.014420</td>\n      <td>-0.054993</td>\n      <td>...</td>\n      <td>0.081007</td>\n      <td>-0.002164</td>\n      <td>0.060377</td>\n      <td>0.080294</td>\n      <td>-0.139369</td>\n      <td>-0.150245</td>\n      <td>0.078657</td>\n      <td>0.024194</td>\n      <td>0.062180</td>\n      <td>0.036039</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>male</td>\n      <td>-0.074126</td>\n      <td>-0.000669</td>\n      <td>0.004166</td>\n      <td>-0.082413</td>\n      <td>-0.096091</td>\n      <td>-0.021992</td>\n      <td>0.009714</td>\n      <td>-0.056961</td>\n      <td>...</td>\n      <td>0.050497</td>\n      <td>0.038932</td>\n      <td>0.023520</td>\n      <td>-0.090260</td>\n      <td>-0.147692</td>\n      <td>-0.008296</td>\n      <td>0.007609</td>\n      <td>-0.026687</td>\n      <td>-0.017523</td>\n      <td>-0.038310</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>male</td>\n      <td>-0.166220</td>\n      <td>0.042769</td>\n      <td>-0.031647</td>\n      <td>-0.036892</td>\n      <td>-0.143837</td>\n      <td>-0.040566</td>\n      <td>0.042541</td>\n      <td>-0.122923</td>\n      <td>...</td>\n      <td>0.014732</td>\n      <td>-0.049135</td>\n      <td>0.081770</td>\n      <td>-0.027199</td>\n      <td>-0.096941</td>\n      <td>-0.094661</td>\n      <td>0.057797</td>\n      <td>-0.101063</td>\n      <td>0.061373</td>\n      <td>0.062176</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>male</td>\n      <td>-0.185770</td>\n      <td>0.154008</td>\n      <td>0.073184</td>\n      <td>-0.070829</td>\n      <td>-0.144617</td>\n      <td>-0.019732</td>\n      <td>-0.019418</td>\n      <td>-0.004675</td>\n      <td>...</td>\n      <td>0.093317</td>\n      <td>0.035101</td>\n      <td>-0.147997</td>\n      <td>-0.046010</td>\n      <td>-0.087777</td>\n      <td>-0.100660</td>\n      <td>0.036190</td>\n      <td>0.012158</td>\n      <td>0.032304</td>\n      <td>0.085996</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>400</td>\n      <td>female</td>\n      <td>0.039844</td>\n      <td>0.070357</td>\n      <td>0.130196</td>\n      <td>-0.007683</td>\n      <td>-0.077825</td>\n      <td>-0.021298</td>\n      <td>-0.024133</td>\n      <td>-0.085105</td>\n      <td>...</td>\n      <td>0.105510</td>\n      <td>0.081928</td>\n      <td>-0.033337</td>\n      <td>-0.023604</td>\n      <td>-0.167003</td>\n      <td>-0.059075</td>\n      <td>0.053074</td>\n      <td>0.080940</td>\n      <td>0.011467</td>\n      <td>-0.021999</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <td>401</td>\n      <td>female</td>\n      <td>0.001747</td>\n      <td>0.185678</td>\n      <td>0.073260</td>\n      <td>0.042142</td>\n      <td>-0.088674</td>\n      <td>0.028186</td>\n      <td>-0.027830</td>\n      <td>-0.064211</td>\n      <td>...</td>\n      <td>0.123615</td>\n      <td>0.030036</td>\n      <td>0.041442</td>\n      <td>-0.012818</td>\n      <td>-0.119177</td>\n      <td>-0.165786</td>\n      <td>-0.075368</td>\n      <td>-0.017690</td>\n      <td>0.067028</td>\n      <td>0.036452</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>402</td>\n      <td>female</td>\n      <td>-0.091598</td>\n      <td>0.095340</td>\n      <td>0.072125</td>\n      <td>-0.092276</td>\n      <td>-0.079953</td>\n      <td>0.047782</td>\n      <td>-0.004701</td>\n      <td>-0.092005</td>\n      <td>...</td>\n      <td>0.011370</td>\n      <td>0.144719</td>\n      <td>0.089139</td>\n      <td>-0.059767</td>\n      <td>-0.111235</td>\n      <td>-0.055420</td>\n      <td>0.006283</td>\n      <td>0.016900</td>\n      <td>-0.081676</td>\n      <td>0.022809</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>403</td>\n      <td>female</td>\n      <td>-0.018751</td>\n      <td>0.088572</td>\n      <td>0.068894</td>\n      <td>-0.065700</td>\n      <td>-0.115126</td>\n      <td>0.024339</td>\n      <td>-0.028420</td>\n      <td>-0.159320</td>\n      <td>...</td>\n      <td>0.010345</td>\n      <td>0.095309</td>\n      <td>0.012255</td>\n      <td>-0.033010</td>\n      <td>-0.097720</td>\n      <td>-0.218889</td>\n      <td>0.077764</td>\n      <td>0.045943</td>\n      <td>0.010856</td>\n      <td>0.100522</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>404</td>\n      <td>female</td>\n      <td>-0.130889</td>\n      <td>0.093262</td>\n      <td>0.122244</td>\n      <td>-0.110014</td>\n      <td>-0.157625</td>\n      <td>-0.036781</td>\n      <td>0.073908</td>\n      <td>-0.098571</td>\n      <td>...</td>\n      <td>0.003229</td>\n      <td>0.049330</td>\n      <td>0.059733</td>\n      <td>-0.023820</td>\n      <td>-0.098432</td>\n      <td>-0.034316</td>\n      <td>0.075131</td>\n      <td>-0.029204</td>\n      <td>-0.020707</td>\n      <td>0.031028</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>405</td>\n      <td>female</td>\n      <td>-0.037433</td>\n      <td>0.078158</td>\n      <td>0.118061</td>\n      <td>-0.117658</td>\n      <td>-0.194807</td>\n      <td>-0.045464</td>\n      <td>-0.014104</td>\n      <td>-0.158824</td>\n      <td>...</td>\n      <td>0.043848</td>\n      <td>-0.009760</td>\n      <td>0.043486</td>\n      <td>0.020251</td>\n      <td>-0.115420</td>\n      <td>-0.040023</td>\n      <td>0.099409</td>\n      <td>-0.032240</td>\n      <td>0.037601</td>\n      <td>-0.020016</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>406</td>\n      <td>female</td>\n      <td>-0.048322</td>\n      <td>0.063833</td>\n      <td>0.110804</td>\n      <td>-0.096333</td>\n      <td>-0.145212</td>\n      <td>0.008218</td>\n      <td>0.012496</td>\n      <td>-0.056971</td>\n      <td>...</td>\n      <td>0.036783</td>\n      <td>0.064837</td>\n      <td>0.140861</td>\n      <td>-0.063511</td>\n      <td>-0.156427</td>\n      <td>-0.067221</td>\n      <td>0.025938</td>\n      <td>0.016019</td>\n      <td>0.016852</td>\n      <td>0.140859</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>407</td>\n      <td>female</td>\n      <td>-0.102973</td>\n      <td>0.046464</td>\n      <td>0.019684</td>\n      <td>-0.087742</td>\n      <td>-0.086486</td>\n      <td>-0.044946</td>\n      <td>-0.088026</td>\n      <td>-0.248814</td>\n      <td>...</td>\n      <td>0.091401</td>\n      <td>0.096097</td>\n      <td>0.019656</td>\n      <td>0.017288</td>\n      <td>-0.176065</td>\n      <td>-0.060538</td>\n      <td>0.095438</td>\n      <td>-0.088858</td>\n      <td>0.049312</td>\n      <td>0.019009</td>\n    </tr>\n    <tr>\n      <th>407</th>\n      <td>408</td>\n      <td>female</td>\n      <td>-0.134824</td>\n      <td>0.093314</td>\n      <td>0.103505</td>\n      <td>-0.054522</td>\n      <td>-0.066692</td>\n      <td>-0.039892</td>\n      <td>-0.005544</td>\n      <td>-0.140088</td>\n      <td>...</td>\n      <td>-0.043587</td>\n      <td>0.042913</td>\n      <td>-0.062721</td>\n      <td>-0.065257</td>\n      <td>-0.232838</td>\n      <td>-0.136345</td>\n      <td>0.017268</td>\n      <td>-0.102133</td>\n      <td>0.014161</td>\n      <td>0.011314</td>\n    </tr>\n    <tr>\n      <th>408</th>\n      <td>409</td>\n      <td>female</td>\n      <td>-0.086950</td>\n      <td>0.104945</td>\n      <td>0.093125</td>\n      <td>-0.138791</td>\n      <td>-0.111283</td>\n      <td>-0.078399</td>\n      <td>-0.063179</td>\n      <td>-0.155705</td>\n      <td>...</td>\n      <td>0.125923</td>\n      <td>0.069823</td>\n      <td>0.081179</td>\n      <td>0.004632</td>\n      <td>-0.121078</td>\n      <td>-0.018539</td>\n      <td>0.092550</td>\n      <td>-0.081236</td>\n      <td>0.073335</td>\n      <td>0.056886</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 130 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0 Unnamed: 1         0         1         2         3         4  \\\n10           11       male -0.101760  0.095119  0.022390  0.033455 -0.028316   \n11           12       male -0.126957  0.065444 -0.014750 -0.062769  0.006243   \n12           13       male  0.021787  0.047769  0.031156 -0.036925 -0.125392   \n13           14       male -0.091019  0.042462 -0.061052 -0.070249 -0.050925   \n14           15       male -0.082929  0.058382  0.008007 -0.010675 -0.099150   \n..          ...        ...       ...       ...       ...       ...       ...   \n795         796     female -0.164731  0.064301  0.058630 -0.017420 -0.157600   \n796         797     female -0.095308  0.051095  0.092913 -0.101745 -0.083153   \n797         798     female -0.202852  0.037039  0.079731 -0.047156 -0.140062   \n798         799     female -0.088300  0.063530  0.049627 -0.026011 -0.172773   \n799         800     female -0.156201  0.055165  0.142716 -0.115393 -0.128982   \n\n            5         6         7  ...       118       119       120  \\\n10  -0.071314 -0.076263 -0.173371  ...  0.103842  0.064531 -0.038534   \n11   0.033722 -0.069378 -0.109074  ...  0.079223  0.102630  0.014118   \n12   0.009113 -0.014069 -0.153379  ...  0.057198  0.043197 -0.046054   \n13  -0.114522 -0.001090 -0.061084  ...  0.042027 -0.003301  0.002241   \n14  -0.102433  0.037710 -0.125727  ...  0.037042 -0.006108 -0.022526   \n..        ...       ...       ...  ...       ...       ...       ...   \n795 -0.022536  0.002864 -0.072739  ...  0.095115  0.007198 -0.004655   \n796 -0.028159  0.009090 -0.114513  ...  0.056078  0.119846  0.087470   \n797 -0.080246  0.057668 -0.122083  ...  0.066954  0.035684 -0.023112   \n798  0.086218  0.042710 -0.161852  ...  0.039460  0.067547  0.040426   \n799 -0.139830 -0.037305 -0.101402  ...  0.024955  0.066980 -0.002332   \n\n          121       122       123       124       125       126       127  \n10   0.045669 -0.195098 -0.065993  0.086835  0.045227  0.134832  0.053776  \n11   0.011191 -0.158518 -0.084066 -0.004959 -0.025286 -0.003429  0.057033  \n12   0.062767 -0.116895 -0.179019 -0.045612 -0.052743  0.034252  0.046343  \n13  -0.001005 -0.095180 -0.107603  0.031764 -0.026397  0.049204 -0.050450  \n14  -0.046081 -0.123925 -0.124878 -0.028671 -0.026378  0.048825 -0.025185  \n..        ...       ...       ...       ...       ...       ...       ...  \n795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n\n[780 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>118</th>\n      <th>119</th>\n      <th>120</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>male</td>\n      <td>-0.101760</td>\n      <td>0.095119</td>\n      <td>0.022390</td>\n      <td>0.033455</td>\n      <td>-0.028316</td>\n      <td>-0.071314</td>\n      <td>-0.076263</td>\n      <td>-0.173371</td>\n      <td>...</td>\n      <td>0.103842</td>\n      <td>0.064531</td>\n      <td>-0.038534</td>\n      <td>0.045669</td>\n      <td>-0.195098</td>\n      <td>-0.065993</td>\n      <td>0.086835</td>\n      <td>0.045227</td>\n      <td>0.134832</td>\n      <td>0.053776</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>male</td>\n      <td>-0.126957</td>\n      <td>0.065444</td>\n      <td>-0.014750</td>\n      <td>-0.062769</td>\n      <td>0.006243</td>\n      <td>0.033722</td>\n      <td>-0.069378</td>\n      <td>-0.109074</td>\n      <td>...</td>\n      <td>0.079223</td>\n      <td>0.102630</td>\n      <td>0.014118</td>\n      <td>0.011191</td>\n      <td>-0.158518</td>\n      <td>-0.084066</td>\n      <td>-0.004959</td>\n      <td>-0.025286</td>\n      <td>-0.003429</td>\n      <td>0.057033</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>male</td>\n      <td>0.021787</td>\n      <td>0.047769</td>\n      <td>0.031156</td>\n      <td>-0.036925</td>\n      <td>-0.125392</td>\n      <td>0.009113</td>\n      <td>-0.014069</td>\n      <td>-0.153379</td>\n      <td>...</td>\n      <td>0.057198</td>\n      <td>0.043197</td>\n      <td>-0.046054</td>\n      <td>0.062767</td>\n      <td>-0.116895</td>\n      <td>-0.179019</td>\n      <td>-0.045612</td>\n      <td>-0.052743</td>\n      <td>0.034252</td>\n      <td>0.046343</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>male</td>\n      <td>-0.091019</td>\n      <td>0.042462</td>\n      <td>-0.061052</td>\n      <td>-0.070249</td>\n      <td>-0.050925</td>\n      <td>-0.114522</td>\n      <td>-0.001090</td>\n      <td>-0.061084</td>\n      <td>...</td>\n      <td>0.042027</td>\n      <td>-0.003301</td>\n      <td>0.002241</td>\n      <td>-0.001005</td>\n      <td>-0.095180</td>\n      <td>-0.107603</td>\n      <td>0.031764</td>\n      <td>-0.026397</td>\n      <td>0.049204</td>\n      <td>-0.050450</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>male</td>\n      <td>-0.082929</td>\n      <td>0.058382</td>\n      <td>0.008007</td>\n      <td>-0.010675</td>\n      <td>-0.099150</td>\n      <td>-0.102433</td>\n      <td>0.037710</td>\n      <td>-0.125727</td>\n      <td>...</td>\n      <td>0.037042</td>\n      <td>-0.006108</td>\n      <td>-0.022526</td>\n      <td>-0.046081</td>\n      <td>-0.123925</td>\n      <td>-0.124878</td>\n      <td>-0.028671</td>\n      <td>-0.026378</td>\n      <td>0.048825</td>\n      <td>-0.025185</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>796</td>\n      <td>female</td>\n      <td>-0.164731</td>\n      <td>0.064301</td>\n      <td>0.058630</td>\n      <td>-0.017420</td>\n      <td>-0.157600</td>\n      <td>-0.022536</td>\n      <td>0.002864</td>\n      <td>-0.072739</td>\n      <td>...</td>\n      <td>0.095115</td>\n      <td>0.007198</td>\n      <td>-0.004655</td>\n      <td>0.023957</td>\n      <td>-0.170753</td>\n      <td>-0.136630</td>\n      <td>0.041614</td>\n      <td>0.031600</td>\n      <td>0.019064</td>\n      <td>0.004384</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>797</td>\n      <td>female</td>\n      <td>-0.095308</td>\n      <td>0.051095</td>\n      <td>0.092913</td>\n      <td>-0.101745</td>\n      <td>-0.083153</td>\n      <td>-0.028159</td>\n      <td>0.009090</td>\n      <td>-0.114513</td>\n      <td>...</td>\n      <td>0.056078</td>\n      <td>0.119846</td>\n      <td>0.087470</td>\n      <td>0.017481</td>\n      <td>-0.096594</td>\n      <td>-0.084553</td>\n      <td>0.037709</td>\n      <td>0.030732</td>\n      <td>-0.083713</td>\n      <td>0.064970</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>798</td>\n      <td>female</td>\n      <td>-0.202852</td>\n      <td>0.037039</td>\n      <td>0.079731</td>\n      <td>-0.047156</td>\n      <td>-0.140062</td>\n      <td>-0.080246</td>\n      <td>0.057668</td>\n      <td>-0.122083</td>\n      <td>...</td>\n      <td>0.066954</td>\n      <td>0.035684</td>\n      <td>-0.023112</td>\n      <td>-0.030452</td>\n      <td>-0.154243</td>\n      <td>-0.188270</td>\n      <td>0.071086</td>\n      <td>0.037384</td>\n      <td>-0.006257</td>\n      <td>0.039977</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>799</td>\n      <td>female</td>\n      <td>-0.088300</td>\n      <td>0.063530</td>\n      <td>0.049627</td>\n      <td>-0.026011</td>\n      <td>-0.172773</td>\n      <td>0.086218</td>\n      <td>0.042710</td>\n      <td>-0.161852</td>\n      <td>...</td>\n      <td>0.039460</td>\n      <td>0.067547</td>\n      <td>0.040426</td>\n      <td>0.028007</td>\n      <td>-0.154515</td>\n      <td>-0.127736</td>\n      <td>0.046967</td>\n      <td>0.009701</td>\n      <td>-0.016942</td>\n      <td>0.048071</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>800</td>\n      <td>female</td>\n      <td>-0.156201</td>\n      <td>0.055165</td>\n      <td>0.142716</td>\n      <td>-0.115393</td>\n      <td>-0.128982</td>\n      <td>-0.139830</td>\n      <td>-0.037305</td>\n      <td>-0.101402</td>\n      <td>...</td>\n      <td>0.024955</td>\n      <td>0.066980</td>\n      <td>-0.002332</td>\n      <td>-0.045738</td>\n      <td>-0.110557</td>\n      <td>-0.014995</td>\n      <td>-0.002124</td>\n      <td>-0.010298</td>\n      <td>-0.028856</td>\n      <td>0.075323</td>\n    </tr>\n  </tbody>\n</table>\n<p>780 rows × 130 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:, 2:].values\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 1].values\n",
    "y_test = test_df.iloc[:, 1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10175994  0.09511936  0.02239008 ...  0.04522717  0.13483205\n",
      "   0.0537758 ]\n",
      " [-0.12695727  0.06544437 -0.01474994 ... -0.02528606 -0.00342875\n",
      "   0.05703329]\n",
      " [ 0.02178704  0.0477692   0.03115616 ... -0.05274343  0.03425189\n",
      "   0.04634342]\n",
      " ...\n",
      " [-0.20285167  0.0370395   0.07973114 ...  0.03738441 -0.00625749\n",
      "   0.03997689]\n",
      " [-0.08829999  0.06353012  0.04962703 ...  0.00970074 -0.01694169\n",
      "   0.04807128]\n",
      " [-0.15620135  0.05516458  0.14271647 ... -0.0102984  -0.02885648\n",
      "   0.0753232 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06641996  0.15161145  0.02773961 ... -0.07640016  0.10749723\n",
      "   0.00156654]\n",
      " [-0.03061386  0.04966652  0.00808374 ...  0.0176384   0.08060966\n",
      "  -0.01592966]\n",
      " [-0.09617768  0.06112669  0.03532604 ...  0.01739147  0.057652\n",
      "   0.08611634]\n",
      " ...\n",
      " [-0.1029727   0.046464    0.01968378 ... -0.08885815  0.04931188\n",
      "   0.01900873]\n",
      " [-0.13482405  0.0933139   0.10350525 ... -0.1021332   0.01416106\n",
      "   0.0113144 ]\n",
      " [-0.08694977  0.1049448   0.09312473 ... -0.0812363   0.0733347\n",
      "   0.05688613]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding the Dependent Variable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
